{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da5672b",
   "metadata": {},
   "source": [
    "# End-to-End Machine Learning Project\n",
    "This notebook demonstrates an end-to-end machine learning workflow, including data preprocessing, model training, and GUI development. The workflow is modular and follows clean code practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0da7c5",
   "metadata": {},
   "source": [
    "## Load and Inspect the Dataset\n",
    "Load the dataset using pandas, inspect its structure, and display summary statistics. This step ensures data quality and provides insights into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb63e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/alandgailan/Desktop/mushroom_classification_model/mushrooms_decoded.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values:\", missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f7496",
   "metadata": {},
   "source": [
    "## Handle Missing or Incorrect Data\n",
    "Identify and handle missing or incorrect data using appropriate techniques such as imputation or removal. This step ensures the dataset is clean and ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce856874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "data = data.dropna()\n",
    "\n",
    "# Verify no missing values remain\n",
    "missing_values_after = data.isnull().sum()\n",
    "print(\"Missing values after handling:\", missing_values_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670345d4",
   "metadata": {},
   "source": [
    "## Normalize and Transform Values\n",
    "Normalize numerical values and encode categorical variables for machine learning compatibility. This step ensures the data is in a format suitable for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Normalize numerical values\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0da2b29",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "Select the most relevant features for training using techniques like correlation analysis or feature importance. This step reduces dimensionality and improves model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "correlation_matrix = data.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# Select features based on correlation\n",
    "target = 'target'\n",
    "features = correlation_matrix[target][correlation_matrix[target] > 0.1].index.tolist()\n",
    "print('Selected features:', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0e010",
   "metadata": {},
   "source": [
    "## Train a Machine Learning Model\n",
    "Train a machine learning model using scikit-learn, evaluate its performance, and optimize hyperparameters. This step builds the predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ea441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Model accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96941e",
   "metadata": {},
   "source": [
    "## Save the Trained Model\n",
    "Save the trained model using pickle or joblib for later use in the GUI application. This step ensures the model can be reused without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba3285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "model_path = '/Users/alandgailan/Desktop/mushroom_classification_model/mushroom_model.pkl'\n",
    "with open(model_path, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42edb57",
   "metadata": {},
   "source": [
    "## Build a GUI for Predictions\n",
    "Create a GUI using Tkinter, Streamlit, or Gradio to load the trained model, accept user input, and display predictions. This step provides an interactive interface for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a46a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "model_path = 'path_to_your_model.pkl'  # Update this with your model path\n",
    "with open(model_path, 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "\n",
    "# Define the feature names based on your model\n",
    "features = ['feature1', 'feature2', 'feature3']  # Update this with your feature names\n",
    "\n",
    "# Streamlit GUI\n",
    "st.title('Mushroom Classification Prediction')\n",
    "st.write('Enter the features of the mushroom to predict its edibility.')\n",
    "\n",
    "# User input\n",
    "user_input = {}\n",
    "for feature in features:\n",
    "    user_input[feature] = st.number_input(f'Enter {feature}:')\n",
    "\n",
    "# Predict\n",
    "if st.button('Predict'):\n",
    "    input_data = np.array([list(user_input.values())]).reshape(1, -1)\n",
    "    prediction = loaded_model.predict(input_data)[0]\n",
    "    st.write('Prediction:', 'Edible' if prediction == 1 else 'Poisonous')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
